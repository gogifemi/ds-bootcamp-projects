{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on Prediction for Customer Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project builds on my prior experience with machine learning methods, where I contributed to a group project predicting the success of Kickstarter campaigns. My responsibilities included conducting exploratory data analysis (EDA) and training an XGBoost model. For this solo project, I apply a similar process to address the business-critical problem of customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I tackle the challenge of predicting customer churn by building a Customer Churn Prediction model. Customer churn refers to the rate at which customers stop doing business with a company, often measured as the number of customers who leave or fail to renew their subscription. Understanding and predicting churn is crucial for businesses aiming to retain customers and improve long-term growth.\n",
    "\n",
    "__INFORMATION ON DATA__   \n",
    "The data is retreived from [Kaggle](https://www.kaggle.com/datasets/willianoliveiragibin/customer-churn) along with the description of the columns. And the dataset is defined as \"The Customer Churn Classification dataset is a vital resource for businesses seeking to understand and predict customer churn, a critical metric that represents the rate at which customers stop doing business with a company over a given period. Understanding churn is essential for any customer-focused company, as retaining customers is generally more cost-effective than acquiring new ones. The dataset is designed to provide a detailed view of customer characteristics and behaviors that could potentially lead to churn, allowing companies to take preemptive action to improve customer retention.\"\n",
    "\n",
    "__BUSINESS CASE__    \n",
    "You work as a Data Scientist for a subscription-based company that experiences fluctuations in customer retention, with a mix of new, loyal, and departing customers. The company has tasked you with developing a predictive model to estimate the likelihood of customer churn â€” identifying which customers are at risk of canceling their subscriptions.\n",
    "\n",
    "Understanding and predicting churn is critical, as mentioned above, for the company to implement targeted retention strategies, as retaining existing customers is often more cost-effective than acquiring new ones. Beyond prediction, the company seeks insights into the key factors influencing churn, such as customer demographics, usage patterns, and service satisfaction. These insights will guide data-driven interventions aimed at improving customer retention and driving long-term business growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, r2_score, mean_squared_error, confusion_matrix, log_loss, classification_report, roc_curve\n",
    "# from xgboost import XGBClassifier\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides an overview of the dataset, including its structure, the number of rows and columns, and a preview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>747</td>\n",
       "      <td>15787619</td>\n",
       "      <td>Hsieh</td>\n",
       "      <td>844</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>160980.03</td>\n",
       "      <td>145936.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620</td>\n",
       "      <td>15770309</td>\n",
       "      <td>McDonald</td>\n",
       "      <td>656</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>151762.74</td>\n",
       "      <td>127014.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1679</td>\n",
       "      <td>15569178</td>\n",
       "      <td>Kharlamov</td>\n",
       "      <td>570</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>82767.42</td>\n",
       "      <td>71811.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>15795519</td>\n",
       "      <td>Vasiliev</td>\n",
       "      <td>716</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>128743.80</td>\n",
       "      <td>197322.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2137</td>\n",
       "      <td>15621893</td>\n",
       "      <td>Bellucci</td>\n",
       "      <td>727</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>133550.67</td>\n",
       "      <td>46941.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2142</td>\n",
       "      <td>15758372</td>\n",
       "      <td>Wallace</td>\n",
       "      <td>674</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55753.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3331</td>\n",
       "      <td>15657439</td>\n",
       "      <td>Chao</td>\n",
       "      <td>738</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47799.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3513</td>\n",
       "      <td>15657779</td>\n",
       "      <td>Boylan</td>\n",
       "      <td>806</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86994.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3518</td>\n",
       "      <td>15757821</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>771</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41542.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3687</td>\n",
       "      <td>15665327</td>\n",
       "      <td>Cattaneo</td>\n",
       "      <td>706</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>176139.50</td>\n",
       "      <td>129654.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4557</td>\n",
       "      <td>15796231</td>\n",
       "      <td>Nwankwo</td>\n",
       "      <td>681</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>98894.39</td>\n",
       "      <td>9596.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4717</td>\n",
       "      <td>15805764</td>\n",
       "      <td>Hallahan</td>\n",
       "      <td>646</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52795.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7335</td>\n",
       "      <td>15759133</td>\n",
       "      <td>Vaguine</td>\n",
       "      <td>616</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27308.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7723</td>\n",
       "      <td>15570086</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>684</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>90544.00</td>\n",
       "      <td>4777.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8523</td>\n",
       "      <td>15619892</td>\n",
       "      <td>Page</td>\n",
       "      <td>644</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59172.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9030</td>\n",
       "      <td>15722701</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>594</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>132694.73</td>\n",
       "      <td>167689.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9502</td>\n",
       "      <td>15634146</td>\n",
       "      <td>Hou</td>\n",
       "      <td>835</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>142872.36</td>\n",
       "      <td>117632.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9521</td>\n",
       "      <td>15673180</td>\n",
       "      <td>Onyekaozulu</td>\n",
       "      <td>727</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>93816.70</td>\n",
       "      <td>126172.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9527</td>\n",
       "      <td>15665521</td>\n",
       "      <td>Chiazagomekpele</td>\n",
       "      <td>642</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>111183.53</td>\n",
       "      <td>10063.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9573</td>\n",
       "      <td>15641688</td>\n",
       "      <td>Collier</td>\n",
       "      <td>644</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59645.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId          Surname  CreditScore Geography  Gender  \\\n",
       "0         747    15787619            Hsieh          844    France    Male   \n",
       "1        1620    15770309         McDonald          656    France    Male   \n",
       "2        1679    15569178        Kharlamov          570    France  Female   \n",
       "3        2022    15795519         Vasiliev          716   Germany  Female   \n",
       "4        2137    15621893         Bellucci          727    France    Male   \n",
       "5        2142    15758372          Wallace          674    France    Male   \n",
       "6        3331    15657439             Chao          738    France    Male   \n",
       "7        3513    15657779           Boylan          806     Spain    Male   \n",
       "8        3518    15757821          Burgess          771     Spain    Male   \n",
       "9        3687    15665327         Cattaneo          706    France    Male   \n",
       "10       4557    15796231          Nwankwo          681    France  Female   \n",
       "11       4717    15805764         Hallahan          646    France    Male   \n",
       "12       7335    15759133          Vaguine          616    France    Male   \n",
       "13       7723    15570086            Lynch          684   Germany    Male   \n",
       "14       8523    15619892             Page          644     Spain    Male   \n",
       "15       9030    15722701            Bruno          594   Germany    Male   \n",
       "16       9502    15634146              Hou          835   Germany    Male   \n",
       "17       9521    15673180      Onyekaozulu          727   Germany  Female   \n",
       "18       9527    15665521  Chiazagomekpele          642   Germany    Male   \n",
       "19       9573    15641688          Collier          644     Spain    Male   \n",
       "\n",
       "    Age  Tenure    Balance  EstimatedSalary  Exited  \n",
       "0    18       2  160980.03        145936.28       0  \n",
       "1    18      10  151762.74        127014.32       0  \n",
       "2    18       4   82767.42         71811.90       0  \n",
       "3    18       3  128743.80        197322.13       0  \n",
       "4    18       4  133550.67         46941.41       0  \n",
       "5    18       7       0.00         55753.12       1  \n",
       "6    18       4       0.00         47799.15       0  \n",
       "7    18       3       0.00         86994.54       0  \n",
       "8    18       1       0.00         41542.95       0  \n",
       "9    18       2  176139.50        129654.22       0  \n",
       "10   18       1   98894.39          9596.40       0  \n",
       "11   18      10       0.00         52795.15       0  \n",
       "12   18       6       0.00         27308.58       0  \n",
       "13   18       9   90544.00          4777.23       0  \n",
       "14   18       8       0.00         59172.42       0  \n",
       "15   18       1  132694.73        167689.56       0  \n",
       "16   18       2  142872.36        117632.63       0  \n",
       "17   18       2   93816.70        126172.11       0  \n",
       "18   18       5  111183.53         10063.75       0  \n",
       "19   18       7       0.00         59645.24       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv file and display\n",
    "df = pd.read_csv(\"data_churn/customer_churn.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two categorical features: `Geography` and `Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the descriptions of the columns:\n",
    "\n",
    "| Column name | Description |\n",
    "| --- | ----------- |\n",
    "| CustomerId | A unique identifier for each customer |\n",
    "| Surname | Contains the surname of the customer |\n",
    "| CreditScore | A key financial indicator, the credit score reflects a customer's financial health |\n",
    "| Geography | The geographical location of customers |\n",
    "| Gender | Identifies the gender of the customer |\n",
    "| Age | Contains the age of the customer |\n",
    "| Tenure | Reflects how long a customer has been with the company |\n",
    "| Balance | The account balance of customers |\n",
    "| EstimatedSalary | A customer's estimated salary provides an indication of their financial well-being |\n",
    "| Exited | This is the target column, which indicates whether the customre churned (1 for churned and 0 for not churned) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10000 rows and 11 columns in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# check data-types and for possible missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important Notes on Data__     \n",
    "- There are no missing values\n",
    "- Only the `Geography` and `Gender` columns need to be converted into dummies to make it easier to work with the dataset.\n",
    "\n",
    "This will be done in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial assumptions about dataset\n",
    "\n",
    "Based on the initial findings, we can make the following assumptions:\n",
    "\n",
    "1. The dataset is complete.\n",
    "2. The dataset is accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our hypotheses and address some of the company's concerns, we will now explore the data in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CustomerId'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\admin\\dataScienceBootcamp\\my_eda_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CustomerId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# check for duplicate rows in video_id column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCustomerId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32mc:\\Users\\admin\\dataScienceBootcamp\\my_eda_project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\admin\\dataScienceBootcamp\\my_eda_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CustomerId'"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows in video_id column\n",
    "df[\"CustomerId\"].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dropping columns__     \n",
    "It is not necessary to include all columns in our analysis. By excluding certain columns, we can streamline the exploration process and focus on the most relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't need\n",
    "df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>160980.03</td>\n",
       "      <td>145936.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>656</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>151762.74</td>\n",
       "      <td>127014.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>82767.42</td>\n",
       "      <td>71811.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>716</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>128743.80</td>\n",
       "      <td>197322.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>727</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>133550.67</td>\n",
       "      <td>46941.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  EstimatedSalary  \\\n",
       "0          844    France    Male   18       2  160980.03        145936.28   \n",
       "1          656    France    Male   18      10  151762.74        127014.32   \n",
       "2          570    France  Female   18       4   82767.42         71811.90   \n",
       "3          716   Germany  Female   18       3  128743.80        197322.13   \n",
       "4          727    France    Male   18       4  133550.67         46941.41   \n",
       "\n",
       "   Exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dealing with duplicate rows__  \n",
    "It is necessary to identify and remove any duplicate rows in order to ensure the accuracy and reliability of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
